{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import loadtxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.3.1-cp38-cp38-macosx_10_14_x86_64.whl (165.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 165.2 MB 3.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting astunparse==1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting tensorflow-estimator<2.4.0,>=2.3.0\n",
      "  Downloading tensorflow_estimator-2.3.0-py2.py3-none-any.whl (459 kB)\n",
      "\u001b[K     |████████████████████████████████| 459 kB 3.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy<1.19.0,>=1.16.0\n",
      "  Downloading numpy-1.18.5-cp38-cp38-macosx_10_9_x86_64.whl (15.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 15.1 MB 4.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting grpcio>=1.8.6\n",
      "  Downloading grpcio-1.32.0-cp38-cp38-macosx_10_9_x86_64.whl (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 3.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras-preprocessing<1.2,>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 2.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting absl-py>=0.7.0\n",
      "  Downloading absl_py-0.10.0-py3-none-any.whl (127 kB)\n",
      "\u001b[K     |████████████████████████████████| 127 kB 3.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /Users/divyapanchal/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /Users/divyapanchal/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /Users/divyapanchal/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /Users/divyapanchal/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.35.1)\n",
      "Collecting google-pasta>=0.1.8\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 3.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 3.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gast==0.3.3\n",
      "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting tensorboard<3,>=2.3.0\n",
      "  Downloading tensorboard-2.3.0-py3-none-any.whl (6.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.8 MB 3.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.13.0-cp38-cp38-macosx_10_9_x86_64.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 3.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.15 in /Users/divyapanchal/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.0.1)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.7.0-py3-none-any.whl (779 kB)\n",
      "\u001b[K     |████████████████████████████████| 779 kB 3.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /Users/divyapanchal/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (49.6.0.post20200925)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.2.2-py3-none-any.whl (88 kB)\n",
      "\u001b[K     |████████████████████████████████| 88 kB 3.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /Users/divyapanchal/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.24.0)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.22.1-py2.py3-none-any.whl (114 kB)\n",
      "\u001b[K     |████████████████████████████████| 114 kB 3.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.1-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/divyapanchal/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/divyapanchal/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/divyapanchal/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.25.10)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/divyapanchal/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.10)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[K     |████████████████████████████████| 155 kB 3.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting rsa<5,>=3.1.4; python_version >= \"3.5\"\n",
      "  Downloading rsa-4.6-py3-none-any.whl (47 kB)\n",
      "\u001b[K     |████████████████████████████████| 47 kB 3.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.1.1-py3-none-any.whl (10 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[K     |████████████████████████████████| 77 kB 4.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "\u001b[K     |████████████████████████████████| 147 kB 3.6 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: termcolor\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4830 sha256=5b545e29fcd5142bd65d111926e7912fee4881ef1aebf6fcec7ed622d02fe03b\n",
      "  Stored in directory: /Users/divyapanchal/Library/Caches/pip/wheels/a0/16/9c/5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
      "Successfully built termcolor\n",
      "Installing collected packages: astunparse, tensorflow-estimator, numpy, grpcio, keras-preprocessing, absl-py, termcolor, google-pasta, opt-einsum, gast, tensorboard-plugin-wit, protobuf, markdown, pyasn1, pyasn1-modules, rsa, cachetools, google-auth, oauthlib, requests-oauthlib, google-auth-oauthlib, tensorboard, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.1\n",
      "    Uninstalling numpy-1.19.1:\n",
      "      Successfully uninstalled numpy-1.19.1\n",
      "Successfully installed absl-py-0.10.0 astunparse-1.6.3 cachetools-4.1.1 gast-0.3.3 google-auth-1.22.1 google-auth-oauthlib-0.4.1 google-pasta-0.2.0 grpcio-1.32.0 keras-preprocessing-1.1.2 markdown-3.2.2 numpy-1.18.5 oauthlib-3.1.0 opt-einsum-3.3.0 protobuf-3.13.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.6 tensorboard-2.3.0 tensorboard-plugin-wit-1.7.0 tensorflow-2.3.1 tensorflow-estimator-2.3.0 termcolor-1.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = loadtxt('pima-indians-diabetes.data.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[:,0:8]\n",
    "y = dataset[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "77/77 [==============================] - 0s 492us/step - loss: 0.4368 - accuracy: 0.7969\n",
      "Epoch 2/150\n",
      "77/77 [==============================] - 0s 487us/step - loss: 0.4189 - accuracy: 0.7956\n",
      "Epoch 3/150\n",
      "77/77 [==============================] - 0s 479us/step - loss: 0.4200 - accuracy: 0.8021\n",
      "Epoch 4/150\n",
      "77/77 [==============================] - 0s 482us/step - loss: 0.4227 - accuracy: 0.7943\n",
      "Epoch 5/150\n",
      "77/77 [==============================] - 0s 477us/step - loss: 0.4354 - accuracy: 0.7786\n",
      "Epoch 6/150\n",
      "77/77 [==============================] - 0s 475us/step - loss: 0.4311 - accuracy: 0.8021\n",
      "Epoch 7/150\n",
      "77/77 [==============================] - 0s 478us/step - loss: 0.4310 - accuracy: 0.7995\n",
      "Epoch 8/150\n",
      "77/77 [==============================] - 0s 464us/step - loss: 0.4273 - accuracy: 0.8021\n",
      "Epoch 9/150\n",
      "77/77 [==============================] - 0s 486us/step - loss: 0.4313 - accuracy: 0.7943\n",
      "Epoch 10/150\n",
      "77/77 [==============================] - 0s 485us/step - loss: 0.4207 - accuracy: 0.8060\n",
      "Epoch 11/150\n",
      "77/77 [==============================] - 0s 467us/step - loss: 0.4241 - accuracy: 0.8086\n",
      "Epoch 12/150\n",
      "77/77 [==============================] - 0s 454us/step - loss: 0.4240 - accuracy: 0.7917\n",
      "Epoch 13/150\n",
      "77/77 [==============================] - 0s 485us/step - loss: 0.4238 - accuracy: 0.8008\n",
      "Epoch 14/150\n",
      "77/77 [==============================] - 0s 543us/step - loss: 0.4176 - accuracy: 0.7917\n",
      "Epoch 15/150\n",
      "77/77 [==============================] - 0s 478us/step - loss: 0.4213 - accuracy: 0.7995\n",
      "Epoch 16/150\n",
      "77/77 [==============================] - 0s 469us/step - loss: 0.4150 - accuracy: 0.8021\n",
      "Epoch 17/150\n",
      "77/77 [==============================] - 0s 479us/step - loss: 0.4118 - accuracy: 0.8008\n",
      "Epoch 18/150\n",
      "77/77 [==============================] - 0s 492us/step - loss: 0.4126 - accuracy: 0.8047\n",
      "Epoch 19/150\n",
      "77/77 [==============================] - 0s 469us/step - loss: 0.4203 - accuracy: 0.8060\n",
      "Epoch 20/150\n",
      "77/77 [==============================] - 0s 477us/step - loss: 0.4206 - accuracy: 0.7943\n",
      "Epoch 21/150\n",
      "77/77 [==============================] - 0s 493us/step - loss: 0.4291 - accuracy: 0.8047\n",
      "Epoch 22/150\n",
      "77/77 [==============================] - 0s 483us/step - loss: 0.4213 - accuracy: 0.8086\n",
      "Epoch 23/150\n",
      "77/77 [==============================] - 0s 484us/step - loss: 0.4238 - accuracy: 0.7891\n",
      "Epoch 24/150\n",
      "77/77 [==============================] - 0s 493us/step - loss: 0.4218 - accuracy: 0.8099\n",
      "Epoch 25/150\n",
      "77/77 [==============================] - 0s 470us/step - loss: 0.4161 - accuracy: 0.7930\n",
      "Epoch 26/150\n",
      "77/77 [==============================] - 0s 500us/step - loss: 0.4211 - accuracy: 0.8086\n",
      "Epoch 27/150\n",
      "77/77 [==============================] - 0s 462us/step - loss: 0.4196 - accuracy: 0.7943\n",
      "Epoch 28/150\n",
      "77/77 [==============================] - 0s 470us/step - loss: 0.4425 - accuracy: 0.7904\n",
      "Epoch 29/150\n",
      "77/77 [==============================] - 0s 512us/step - loss: 0.4296 - accuracy: 0.7891\n",
      "Epoch 30/150\n",
      "77/77 [==============================] - 0s 474us/step - loss: 0.4181 - accuracy: 0.7969\n",
      "Epoch 31/150\n",
      "77/77 [==============================] - 0s 537us/step - loss: 0.4141 - accuracy: 0.8047\n",
      "Epoch 32/150\n",
      "77/77 [==============================] - 0s 487us/step - loss: 0.4141 - accuracy: 0.8021\n",
      "Epoch 33/150\n",
      "77/77 [==============================] - 0s 465us/step - loss: 0.4129 - accuracy: 0.8164\n",
      "Epoch 34/150\n",
      "77/77 [==============================] - 0s 464us/step - loss: 0.4325 - accuracy: 0.7917\n",
      "Epoch 35/150\n",
      "77/77 [==============================] - 0s 506us/step - loss: 0.4173 - accuracy: 0.8008\n",
      "Epoch 36/150\n",
      "77/77 [==============================] - 0s 483us/step - loss: 0.4297 - accuracy: 0.7852\n",
      "Epoch 37/150\n",
      "77/77 [==============================] - 0s 491us/step - loss: 0.4242 - accuracy: 0.8021\n",
      "Epoch 38/150\n",
      "77/77 [==============================] - 0s 491us/step - loss: 0.4172 - accuracy: 0.7943\n",
      "Epoch 39/150\n",
      "77/77 [==============================] - 0s 511us/step - loss: 0.4146 - accuracy: 0.8047\n",
      "Epoch 40/150\n",
      "77/77 [==============================] - 0s 471us/step - loss: 0.4166 - accuracy: 0.8125\n",
      "Epoch 41/150\n",
      "77/77 [==============================] - 0s 488us/step - loss: 0.4366 - accuracy: 0.7878\n",
      "Epoch 42/150\n",
      "77/77 [==============================] - 0s 483us/step - loss: 0.4201 - accuracy: 0.7956\n",
      "Epoch 43/150\n",
      "77/77 [==============================] - 0s 472us/step - loss: 0.4238 - accuracy: 0.7917\n",
      "Epoch 44/150\n",
      "77/77 [==============================] - 0s 515us/step - loss: 0.4072 - accuracy: 0.8138\n",
      "Epoch 45/150\n",
      "77/77 [==============================] - 0s 471us/step - loss: 0.4188 - accuracy: 0.8021\n",
      "Epoch 46/150\n",
      "77/77 [==============================] - 0s 466us/step - loss: 0.4200 - accuracy: 0.7995\n",
      "Epoch 47/150\n",
      "77/77 [==============================] - 0s 487us/step - loss: 0.4180 - accuracy: 0.8086\n",
      "Epoch 48/150\n",
      "77/77 [==============================] - 0s 490us/step - loss: 0.4082 - accuracy: 0.8112\n",
      "Epoch 49/150\n",
      "77/77 [==============================] - 0s 509us/step - loss: 0.4361 - accuracy: 0.7786\n",
      "Epoch 50/150\n",
      "77/77 [==============================] - 0s 475us/step - loss: 0.4136 - accuracy: 0.8021\n",
      "Epoch 51/150\n",
      "77/77 [==============================] - 0s 468us/step - loss: 0.4110 - accuracy: 0.8021\n",
      "Epoch 52/150\n",
      "77/77 [==============================] - 0s 476us/step - loss: 0.4359 - accuracy: 0.7930\n",
      "Epoch 53/150\n",
      "77/77 [==============================] - 0s 496us/step - loss: 0.4131 - accuracy: 0.7995\n",
      "Epoch 54/150\n",
      "77/77 [==============================] - 0s 491us/step - loss: 0.4266 - accuracy: 0.7891\n",
      "Epoch 55/150\n",
      "77/77 [==============================] - 0s 471us/step - loss: 0.4156 - accuracy: 0.7982\n",
      "Epoch 56/150\n",
      "77/77 [==============================] - 0s 493us/step - loss: 0.4218 - accuracy: 0.8125\n",
      "Epoch 57/150\n",
      "77/77 [==============================] - 0s 491us/step - loss: 0.4531 - accuracy: 0.7786\n",
      "Epoch 58/150\n",
      "77/77 [==============================] - 0s 494us/step - loss: 0.4123 - accuracy: 0.7891\n",
      "Epoch 59/150\n",
      "77/77 [==============================] - 0s 484us/step - loss: 0.4169 - accuracy: 0.8034\n",
      "Epoch 60/150\n",
      "77/77 [==============================] - 0s 484us/step - loss: 0.4129 - accuracy: 0.8060\n",
      "Epoch 61/150\n",
      "77/77 [==============================] - 0s 485us/step - loss: 0.4170 - accuracy: 0.8034\n",
      "Epoch 62/150\n",
      "77/77 [==============================] - 0s 481us/step - loss: 0.4124 - accuracy: 0.8047\n",
      "Epoch 63/150\n",
      "77/77 [==============================] - 0s 489us/step - loss: 0.4214 - accuracy: 0.7982\n",
      "Epoch 64/150\n",
      "77/77 [==============================] - 0s 489us/step - loss: 0.4231 - accuracy: 0.8099\n",
      "Epoch 65/150\n",
      "77/77 [==============================] - 0s 504us/step - loss: 0.4109 - accuracy: 0.8034\n",
      "Epoch 66/150\n",
      "77/77 [==============================] - 0s 480us/step - loss: 0.4092 - accuracy: 0.8034\n",
      "Epoch 67/150\n",
      "77/77 [==============================] - 0s 540us/step - loss: 0.4153 - accuracy: 0.8021\n",
      "Epoch 68/150\n",
      "77/77 [==============================] - 0s 474us/step - loss: 0.4168 - accuracy: 0.8021\n",
      "Epoch 69/150\n",
      "77/77 [==============================] - 0s 468us/step - loss: 0.4198 - accuracy: 0.8047\n",
      "Epoch 70/150\n",
      "77/77 [==============================] - 0s 492us/step - loss: 0.4089 - accuracy: 0.7982\n",
      "Epoch 71/150\n",
      "77/77 [==============================] - 0s 480us/step - loss: 0.4254 - accuracy: 0.7943\n",
      "Epoch 72/150\n",
      "77/77 [==============================] - 0s 495us/step - loss: 0.4092 - accuracy: 0.8008\n",
      "Epoch 73/150\n",
      "77/77 [==============================] - 0s 472us/step - loss: 0.4124 - accuracy: 0.8008\n",
      "Epoch 74/150\n",
      "77/77 [==============================] - 0s 486us/step - loss: 0.4186 - accuracy: 0.7969\n",
      "Epoch 75/150\n",
      "77/77 [==============================] - 0s 471us/step - loss: 0.4356 - accuracy: 0.7917\n",
      "Epoch 76/150\n",
      "77/77 [==============================] - 0s 470us/step - loss: 0.4091 - accuracy: 0.8099\n",
      "Epoch 77/150\n",
      "77/77 [==============================] - 0s 486us/step - loss: 0.4147 - accuracy: 0.8073\n",
      "Epoch 78/150\n",
      "77/77 [==============================] - 0s 493us/step - loss: 0.4240 - accuracy: 0.7943\n",
      "Epoch 79/150\n",
      "77/77 [==============================] - 0s 466us/step - loss: 0.4149 - accuracy: 0.8138\n",
      "Epoch 80/150\n",
      "77/77 [==============================] - 0s 490us/step - loss: 0.4112 - accuracy: 0.8047\n",
      "Epoch 81/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 0s 487us/step - loss: 0.4452 - accuracy: 0.7708\n",
      "Epoch 82/150\n",
      "77/77 [==============================] - 0s 491us/step - loss: 0.4142 - accuracy: 0.8008\n",
      "Epoch 83/150\n",
      "77/77 [==============================] - 0s 455us/step - loss: 0.4206 - accuracy: 0.8047\n",
      "Epoch 84/150\n",
      "77/77 [==============================] - 0s 455us/step - loss: 0.4046 - accuracy: 0.8060\n",
      "Epoch 85/150\n",
      "77/77 [==============================] - 0s 478us/step - loss: 0.4055 - accuracy: 0.8099\n",
      "Epoch 86/150\n",
      "77/77 [==============================] - 0s 471us/step - loss: 0.4012 - accuracy: 0.8086\n",
      "Epoch 87/150\n",
      "77/77 [==============================] - 0s 459us/step - loss: 0.4126 - accuracy: 0.7969\n",
      "Epoch 88/150\n",
      "77/77 [==============================] - 0s 461us/step - loss: 0.4197 - accuracy: 0.8047\n",
      "Epoch 89/150\n",
      "77/77 [==============================] - 0s 456us/step - loss: 0.4100 - accuracy: 0.8034\n",
      "Epoch 90/150\n",
      "77/77 [==============================] - 0s 471us/step - loss: 0.4096 - accuracy: 0.7982\n",
      "Epoch 91/150\n",
      "77/77 [==============================] - 0s 477us/step - loss: 0.4122 - accuracy: 0.8008\n",
      "Epoch 92/150\n",
      "77/77 [==============================] - 0s 458us/step - loss: 0.4212 - accuracy: 0.7878\n",
      "Epoch 93/150\n",
      "77/77 [==============================] - 0s 473us/step - loss: 0.4120 - accuracy: 0.8047\n",
      "Epoch 94/150\n",
      "77/77 [==============================] - 0s 460us/step - loss: 0.4191 - accuracy: 0.8073\n",
      "Epoch 95/150\n",
      "77/77 [==============================] - 0s 459us/step - loss: 0.4085 - accuracy: 0.8034\n",
      "Epoch 96/150\n",
      "77/77 [==============================] - 0s 454us/step - loss: 0.4115 - accuracy: 0.8112\n",
      "Epoch 97/150\n",
      "77/77 [==============================] - 0s 461us/step - loss: 0.4034 - accuracy: 0.8060\n",
      "Epoch 98/150\n",
      "77/77 [==============================] - 0s 465us/step - loss: 0.4087 - accuracy: 0.8034\n",
      "Epoch 99/150\n",
      "77/77 [==============================] - 0s 457us/step - loss: 0.4089 - accuracy: 0.8138\n",
      "Epoch 100/150\n",
      "77/77 [==============================] - 0s 483us/step - loss: 0.4145 - accuracy: 0.8047\n",
      "Epoch 101/150\n",
      "77/77 [==============================] - 0s 486us/step - loss: 0.4076 - accuracy: 0.8034\n",
      "Epoch 102/150\n",
      "77/77 [==============================] - 0s 458us/step - loss: 0.4034 - accuracy: 0.7995\n",
      "Epoch 103/150\n",
      "77/77 [==============================] - 0s 450us/step - loss: 0.4130 - accuracy: 0.8138\n",
      "Epoch 104/150\n",
      "77/77 [==============================] - 0s 457us/step - loss: 0.4273 - accuracy: 0.7956\n",
      "Epoch 105/150\n",
      "77/77 [==============================] - 0s 481us/step - loss: 0.4222 - accuracy: 0.7891\n",
      "Epoch 106/150\n",
      "77/77 [==============================] - 0s 477us/step - loss: 0.4084 - accuracy: 0.8073\n",
      "Epoch 107/150\n",
      "77/77 [==============================] - 0s 468us/step - loss: 0.4125 - accuracy: 0.7969\n",
      "Epoch 108/150\n",
      "77/77 [==============================] - 0s 474us/step - loss: 0.4137 - accuracy: 0.8099\n",
      "Epoch 109/150\n",
      "77/77 [==============================] - 0s 475us/step - loss: 0.4170 - accuracy: 0.7969\n",
      "Epoch 110/150\n",
      "77/77 [==============================] - 0s 485us/step - loss: 0.4000 - accuracy: 0.8008\n",
      "Epoch 111/150\n",
      "77/77 [==============================] - 0s 518us/step - loss: 0.3988 - accuracy: 0.8125\n",
      "Epoch 112/150\n",
      "77/77 [==============================] - 0s 469us/step - loss: 0.4093 - accuracy: 0.8047\n",
      "Epoch 113/150\n",
      "77/77 [==============================] - 0s 491us/step - loss: 0.4197 - accuracy: 0.7943\n",
      "Epoch 114/150\n",
      "77/77 [==============================] - 0s 479us/step - loss: 0.4189 - accuracy: 0.7943\n",
      "Epoch 115/150\n",
      "77/77 [==============================] - 0s 466us/step - loss: 0.4078 - accuracy: 0.8073\n",
      "Epoch 116/150\n",
      "77/77 [==============================] - 0s 466us/step - loss: 0.4268 - accuracy: 0.7943\n",
      "Epoch 117/150\n",
      "77/77 [==============================] - 0s 477us/step - loss: 0.4184 - accuracy: 0.8034\n",
      "Epoch 118/150\n",
      "77/77 [==============================] - 0s 508us/step - loss: 0.4009 - accuracy: 0.8151\n",
      "Epoch 119/150\n",
      "77/77 [==============================] - 0s 495us/step - loss: 0.4034 - accuracy: 0.8073\n",
      "Epoch 120/150\n",
      "77/77 [==============================] - 0s 469us/step - loss: 0.4205 - accuracy: 0.8047\n",
      "Epoch 121/150\n",
      "77/77 [==============================] - 0s 468us/step - loss: 0.4150 - accuracy: 0.8021\n",
      "Epoch 122/150\n",
      "77/77 [==============================] - 0s 460us/step - loss: 0.4030 - accuracy: 0.8047\n",
      "Epoch 123/150\n",
      "77/77 [==============================] - 0s 464us/step - loss: 0.4074 - accuracy: 0.8164\n",
      "Epoch 124/150\n",
      "77/77 [==============================] - 0s 470us/step - loss: 0.4128 - accuracy: 0.8229\n",
      "Epoch 125/150\n",
      "77/77 [==============================] - 0s 472us/step - loss: 0.4064 - accuracy: 0.8034\n",
      "Epoch 126/150\n",
      "77/77 [==============================] - 0s 473us/step - loss: 0.4133 - accuracy: 0.8060\n",
      "Epoch 127/150\n",
      "77/77 [==============================] - 0s 456us/step - loss: 0.4174 - accuracy: 0.7956\n",
      "Epoch 128/150\n",
      "77/77 [==============================] - 0s 491us/step - loss: 0.4370 - accuracy: 0.7878\n",
      "Epoch 129/150\n",
      "77/77 [==============================] - 0s 471us/step - loss: 0.4044 - accuracy: 0.8060\n",
      "Epoch 130/150\n",
      "77/77 [==============================] - 0s 462us/step - loss: 0.4060 - accuracy: 0.8073\n",
      "Epoch 131/150\n",
      "77/77 [==============================] - 0s 470us/step - loss: 0.4115 - accuracy: 0.8099\n",
      "Epoch 132/150\n",
      "77/77 [==============================] - 0s 454us/step - loss: 0.4057 - accuracy: 0.8099\n",
      "Epoch 133/150\n",
      "77/77 [==============================] - 0s 490us/step - loss: 0.4185 - accuracy: 0.7956\n",
      "Epoch 134/150\n",
      "77/77 [==============================] - 0s 473us/step - loss: 0.4110 - accuracy: 0.8021\n",
      "Epoch 135/150\n",
      "77/77 [==============================] - 0s 477us/step - loss: 0.4024 - accuracy: 0.8034\n",
      "Epoch 136/150\n",
      "77/77 [==============================] - 0s 486us/step - loss: 0.4088 - accuracy: 0.8099\n",
      "Epoch 137/150\n",
      "77/77 [==============================] - 0s 480us/step - loss: 0.4214 - accuracy: 0.8047\n",
      "Epoch 138/150\n",
      "77/77 [==============================] - 0s 461us/step - loss: 0.4097 - accuracy: 0.8112\n",
      "Epoch 139/150\n",
      "77/77 [==============================] - 0s 485us/step - loss: 0.3953 - accuracy: 0.8099\n",
      "Epoch 140/150\n",
      "77/77 [==============================] - 0s 490us/step - loss: 0.4027 - accuracy: 0.7982\n",
      "Epoch 141/150\n",
      "77/77 [==============================] - 0s 466us/step - loss: 0.3984 - accuracy: 0.8099\n",
      "Epoch 142/150\n",
      "77/77 [==============================] - 0s 478us/step - loss: 0.4174 - accuracy: 0.8034\n",
      "Epoch 143/150\n",
      "77/77 [==============================] - 0s 464us/step - loss: 0.4033 - accuracy: 0.8073\n",
      "Epoch 144/150\n",
      "77/77 [==============================] - 0s 477us/step - loss: 0.4018 - accuracy: 0.8021\n",
      "Epoch 145/150\n",
      "77/77 [==============================] - 0s 481us/step - loss: 0.4057 - accuracy: 0.8034\n",
      "Epoch 146/150\n",
      "77/77 [==============================] - 0s 479us/step - loss: 0.4002 - accuracy: 0.7982\n",
      "Epoch 147/150\n",
      "77/77 [==============================] - 0s 489us/step - loss: 0.4039 - accuracy: 0.8203\n",
      "Epoch 148/150\n",
      "77/77 [==============================] - 0s 484us/step - loss: 0.4197 - accuracy: 0.8008\n",
      "Epoch 149/150\n",
      "77/77 [==============================] - 0s 476us/step - loss: 0.4005 - accuracy: 0.8203\n",
      "Epoch 150/150\n",
      "77/77 [==============================] - 0s 482us/step - loss: 0.4052 - accuracy: 0.7904\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fbb48bb3520>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the keras model on the dataset\n",
    "model.fit(X, y, epochs=150, batch_size=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 480us/step - loss: 0.3902 - accuracy: 0.8099\n",
      "Accuracy: 80.99\n"
     ]
    }
   ],
   "source": [
    "# evaluate the keras model\n",
    "_, accuracy = model.evaluate(X, y)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make class predictions with the model\n",
    "predictions = model.predict_classes(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.0, 148.0, 72.0, 35.0, 0.0, 33.6, 0.627, 50.0] => 1 (expected 1)\n",
      "[1.0, 85.0, 66.0, 29.0, 0.0, 26.6, 0.351, 31.0] => 0 (expected 0)\n",
      "[8.0, 183.0, 64.0, 0.0, 0.0, 23.3, 0.672, 32.0] => 1 (expected 1)\n",
      "[1.0, 89.0, 66.0, 23.0, 94.0, 28.1, 0.167, 21.0] => 0 (expected 0)\n",
      "[0.0, 137.0, 40.0, 35.0, 168.0, 43.1, 2.288, 33.0] => 1 (expected 1)\n"
     ]
    }
   ],
   "source": [
    "# summarize the first 5 cases\n",
    "for i in range(5):\n",
    "\tprint('%s => %d (expected %d)' % (X[i].tolist(), predictions[i], y[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
